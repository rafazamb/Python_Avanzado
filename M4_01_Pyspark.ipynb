{"cells":[{"cell_type":"markdown","source":["# Getting started with MLlib - binary classification example"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"b913fae3-9e92-4179-ab1b-9ff70867cdef","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["This tutorial is designed to get you started with Apache Spark MLlib. It investigates a binary classification problem - can you predict if an individual's income is greater than $50,000 based on demographic data? The dataset is from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Adult) and is provided with Databricks Runtime. This notebook demonstrates some of the capabilities available in MLlib, including tools for data preprocessing, machine learning pipelines, and several different machine learning algorithms.\n\nThis notebook includes the following steps:\n\n0. Load the dataset\n0. Feature preprocessing\n0. Define the model\n0. Build the pipeline\n0. Evaluate the model\n0. Hyperparameter tuning\n0. Make predictions and evaluate model performance\n\n## Setup Requirements\nDatabricks Runtime 7.0 or above or Databricks Runtime 7.0 ML or above. If you are running Databricks Runtime 6.x or Databricks Runtime 6.x ML, see ([AWS](https://docs.databricks.com/getting-started/spark/machine-learning.html)|[Azure](https://docs.microsoft.com/azure/databricks/getting-started/spark/machine-learning/)) for the correct notebook."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"90daf6a5-c39a-4631-b27b-90695e341ada","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["## Step 1. Load the dataset"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"d07f0bd0-a5dc-4d3d-9465-7da99a8c9125","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Use Databricks utilities to view the first few rows of the data."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"d77f1cf7-46d7-41da-9d09-de8d8deebbe6","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%fs head --maxBytes=1024 databricks-datasets/adult/adult.data"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"6b6746a2-ccfb-45d3-8395-fa4d8765c461","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Because the dataset does not include column names, create a schema to assign column names and datatypes."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"453ca5bd-975b-462a-8b70-389dfa9bbe68","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["schema = \"\"\"`age` DOUBLE,\n`workclass` STRING,\n`fnlwgt` DOUBLE,\n`education` STRING,\n`education_num` DOUBLE,\n`marital_status` STRING,\n`occupation` STRING,\n`relationship` STRING,\n`race` STRING,\n`sex` STRING,\n`capital_gain` DOUBLE,\n`capital_loss` DOUBLE,\n`hours_per_week` DOUBLE,\n`native_country` STRING,\n`income` STRING\"\"\"\n\ndataset = spark.read.csv(\"/databricks-datasets/adult/adult.data\", schema=schema)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"b45f2567-65cd-4394-a764-ba4f2cb71b42","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Randomly split data into training and test sets, and set seed for reproducibility.\n\nIt's best to split the data before doing any preprocessing. This allows the test dataset to more closely simulate new data when we evaluate the model."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"b100c7a4-e14f-4797-b2f9-3317df2d9462","inputWidgets":{},"title":""}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"df68ae5a-1fc3-4580-b40e-9e7282f8a747","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Data Exploration"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"3685342d-b7ff-4d5d-a3a4-f55b5429202a","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Let's review the data."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"09d904b9-0902-42e2-bd6d-4e75dd48b7cc","inputWidgets":{},"title":""}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"f57c49ec-fdb5-4ac2-a04f-7afda570556a","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"32efa875-21c9-4933-b07f-10ee9df8d633","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"b2524d6c-f54c-4cde-b951-040a4e50ed36","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"cefe5d8b-3f03-4bf7-a0f5-1443224e8ab3","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"610eb2bf-ebf9-4447-9924-4e7549f004d3","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"66247724-7dc0-406c-9fd5-2f0e8f646b96","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"a729bf3e-44cc-4a84-b55f-f8010f5dc93d","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"61d5d61e-2f07-4f3c-aba6-7f7a8d2c8833","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"280939ff-66c2-43ab-9690-f3d4edd54171","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"52377cda-24ed-45de-a6a6-82340d71c374","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"2311b1bb-ecee-4582-bafa-ecddf39a0ccb","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"f6fc6374-33b0-4be7-a201-60a34b824bff","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"e7582b6d-d702-4a12-9a05-c50aeb576b6a","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["What's the distribution of the number of `hours_per_week`?"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"33ba8bb0-3ff4-48bd-8282-07f4f33464ee","inputWidgets":{},"title":""}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"4f50c9e7-016d-466b-a7e2-603ad837d1a8","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["How about `education` status?"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"00836973-8e95-4129-814d-142389f6ca6e","inputWidgets":{},"title":""}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"535eed31-c7ca-415b-b18e-ba48d375cbc9","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Background: Transformers, estimators, and pipelines\n\nThree important concepts in MLlib machine learning that are illustrated in this notebook are **Transformers**, **Estimators**, and **Pipelines**. \n\n- **Transformer**: Takes a DataFrame as input, and returns a new DataFrame. Transformers do not learn any parameters from the data and simply apply rule-based transformations to either prepare data for model training or generate predictions using a trained MLlib model. You call a transformer with a `.transform()` method.\n\n- **Estimator**: Learns (or \"fits\") parameters from your DataFrame via a `.fit()` method and returns a Model, which is a transformer.\n\n- **Pipeline**: Combines multiple steps into a single workflow that can be easily run. Creating a machine learning model typically involves setting up many different steps and iterating over them. Pipelines help you automate this process.\n\nFor more information:\n[ML Pipelines](https://spark.apache.org/docs/latest/ml-pipeline.html#ml-pipelines)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"cd385428-b571-446b-a5ef-e48045a57a06","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["## Step 2. Feature preprocessing \n\nThe goal of this notebook is to build a model that predicts the `income` level from the features included in the dataset (education level, marital status, occupation, and so on). The first step is to manipulate, or preprocess, the features so they are in the format MLlib requires."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"dc0f0451-e585-47f1-aedb-d26fcc4c5731","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### Convert categorical variables to numeric\n\nSome machine learning algorithms, such as linear and logistic regression, require numeric features. The Adult dataset includes categorical features such as education, occupation, and marital status. \n\nThe following code block illustrates how to use `StringIndexer` and `OneHotEncoder` to convert categorical variables into a set of numeric variables that only take on values 0 and 1. \n\n- `StringIndexer` converts a column of string values to a column of label indexes. For example, it might convert the values \"red\", \"blue\", and \"green\" to 0, 1, and 2. \n- `OneHotEncoder` maps a column of category indices to a column of binary vectors, with at most one \"1\" in each row that indicates the category index for that row.\n\nOne-hot encoding in Spark is a two-step process. You first use the StringIndexer, followed by the OneHotEncoder. The following code block defines the StringIndexer and OneHotEncoder but does not apply it to any data yet.\n\nFor more information:   \n[StringIndexer](http://spark.apache.org/docs/latest/ml-features.html#stringindexer)   \n[OneHotEncoder](https://spark.apache.org/docs/latest/ml-features.html#onehotencoder)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"b085060b-d530-4b1f-a322-f01e602caa3d","inputWidgets":{},"title":""}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"4342dc8e-0719-49a6-89c2-92f12d9dcadb","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["In this notebook, we'll build a pipeline combining all of our feature engineering and modeling steps. But let's take a minute to look more closely at how estimators and transformers work by applying the `stringIndexer` estimator that we created in the previous code block.\n\nYou can call the `.fit()` method to return a `StringIndexerModel`, which you can then use to transform the dataset. \n\nThe `.transform()` method of `StringIndexerModel` returns a new DataFrame with the new columns appended. Scroll right to see the new columns if necessary. \n\nFor more information: [StringIndexerModel](https://spark.apache.org/docs/latest/api/java/org/apache/spark/ml/feature/StringIndexerModel.html)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"6d98c7f7-13f3-465c-9848-2f066bed31e0","inputWidgets":{},"title":""}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"51fe5115-d709-4113-acfa-7bf89415961f","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Combine all feature columns into a single feature vector\n\nMost MLlib algorithms require a single features column as input. Each row in this column contains a vector of data points corresponding to the set of features used for prediction. \n\nMLlib provides the `VectorAssembler` transformer to create a single vector column from a list of columns.\n\nThe following code block illustrates how to use VectorAssembler.\n\nFor more information: [VectorAssembler](https://spark.apache.org/docs/latest/ml-features.html#vectorassembler)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"195cbc21-fd10-44c4-a0d9-de0c1291ccf1","inputWidgets":{},"title":""}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"543f9e76-2e8f-4c02-92c0-2fd0eb10b8be","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Step 3. Define the model\n\nThis notebook uses a [logistic regression](https://spark.apache.org/docs/latest/ml-classification-regression.html#logistic-regression) model."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"6bab58b8-6f52-49d2-bf70-a30ad31d240e","inputWidgets":{},"title":""}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"716d0980-a36d-4598-8059-274c33d5e8fd","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Step 4. Build the pipeline\n\nA `Pipeline` is an ordered list of transformers and estimators. You can define a pipeline to automate and ensure repeatability of the transformations to be applied to a dataset. In this step, we define the pipeline and then apply it to the test dataset.\n\nSimilar to what we saw with `StringIndexer`, a `Pipeline` is an estimator. The `pipeline.fit()` method returns a `PipelineModel`, which is a transformer.\n\nFor more information:   \n[Pipeline](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.Pipeline)  \n[PipelineModel](https://spark.apache.org/docs/latest/api/java/org/apache/spark/ml/PipelineModel.html)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"7bad6044-66fb-4adf-a23a-0d122917bb1a","inputWidgets":{},"title":""}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"40bf2ccd-a669-4a64-b519-a1c80586f39a","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Display the predictions from the model. The `features` column is a [sparse vector](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.linalg.SparseVector), which is often the case after one-hot encoding, because there are so many 0 values."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"237e8d49-3a02-48bd-a31f-c1199c899ef5","inputWidgets":{},"title":""}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"2865b194-d79c-48b1-a4e9-79df6fc0814f","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Step 5. Evaluate the model\n\nThe `display` command has a built-in ROC curve option."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"087a5365-c809-472d-b81b-3dfdbc150de9","inputWidgets":{},"title":""}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"4cdd12a3-1fce-4133-a10d-ac242da5ebfa","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["To evaluate the model, we use the `BinaryClassificationEvaluator` to evalute the area under the ROC curve and the `MulticlassClassificationEvaluator` to evalute the accuracy.\n\nFor more information:  \n[BinaryClassificationEvaluator](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.evaluation.BinaryClassificationEvaluator)  \n[MulticlassClassificationEvaluator](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.evaluation.MulticlassClassificationEvaluator)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"ff5d03c5-8aa8-4e8b-bc2a-39ee4893c282","inputWidgets":{},"title":""}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"aab91e24-bbad-4bdb-92c7-71aa97c510be","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Step 6. Hyperparameter tuning\n\nMLlib provides methods to facilitate hyperparameter tuning and cross validation. \n- For hyperparameter tuning, `ParamGridBuilder` lets you define a grid search over a set of model hyperparameters.\n- For cross validation, `CrossValidator` lets you specify an estimator (the pipeline to apply to the input dataset), an evaluator, a grid space of hyperparameters, and the number of folds to use for cross validation.\n  \nFor more information:   \n[Model selection using cross-validation](https://spark.apache.org/docs/latest/ml-tuning.html)  \n[ParamGridBuilder](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#module-pyspark.ml.tuning)  \n[CrossValidator](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.tuning.CrossValidator)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"b5440730-11c9-4e23-8584-7e9bfe31dbb1","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Use `ParamGridBuilder` and `CrossValidator` to tune the model. This example uses three values for `regParam` and three for `elasticNetParam`, for a total of 3 x 3 = 9 hyperparameter combinations for `CrossValidator` to examine."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"ac1420e2-808e-4911-a400-4162af02b213","inputWidgets":{},"title":""}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"5c27edfb-fa5f-47e7-97cc-fd21f59e2cd7","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Whenever you call `CrossValidator` in MLlib, Databricks automatically tracks all of the runs using [MLflow](https://mlflow.org/). You can use the MLflow UI ([AWS](https://docs.databricks.com/applications/mlflow/index.html)|[Azure](https://docs.microsoft.com/azure/databricks/applications/mlflow/)) to compare how each model performed. To look at all the MLflow metrics tracked from the run, click on the `Experiment` icon to the far right above.\n\nIn this example we use the pipeline we created as the estimator."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"9adee129-633e-4770-941c-e967d543adef","inputWidgets":{},"title":""}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"17396c31-c727-4bee-9eca-04ec7a1e53fc","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Step 7. Make predictions and evaluate model performance\nUse the best model identified by the cross-validation to make predictions on the test dataset, and then evaluate the model's performance using the area under the ROC curve."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"aa1d4013-72c6-49bd-bd07-bfca7839f339","inputWidgets":{},"title":""}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"bbefbcc3-17f0-4ba4-927d-73a8e5205dba","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Using SQL commands, you can also display predictions grouped by age and occupation. This requires creating a temporary view of the predictions dataset."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"ff479612-4828-4bb3-b47c-104e2b171b73","inputWidgets":{},"title":""}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"7986e9a4-c0c6-49a7-8ad2-72b9cd98e1b0","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Use SQL queries for displaying predictions"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"09592e73-ceae-43ac-95fb-eb72d16d55ee","inputWidgets":{},"title":""}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000,"implicitDf":true},"nuid":"f59f2425-0d08-40ad-ae6e-7c17319fcc2b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000,"implicitDf":true},"nuid":"a0a487d9-dd2f-44c8-bf29-1db82815fdaa","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000,"implicitDf":true},"nuid":"1ab1972d-5c72-41a4-b2a3-f5ecee5e8b45","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Databricks y Pyspark","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2,"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":719083706487500,"dataframes":["_sqldf"]}},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
